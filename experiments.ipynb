{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# set seed\n",
    "seed = 2023\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "DATA_PATH = \"./data\"\n",
    "\n",
    "URI = \"neo4j://localhost\"\n",
    "AUTH = (\"neo4j\", \"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()\n",
    "\n",
    "data = Data()\n",
    "data.x = []\n",
    "data.y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_index_mappings = {}\n",
    "account_index_mappings = {}\n",
    "user_index_mappings = {}\n",
    "country_index_mappings = {}\n",
    "lob_index_mappings = {}\n",
    "sector_index_mappings = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_TYPE_MAPPINGS = {\n",
    "    'account': 0,\n",
    "    'transaction': 1,\n",
    "    'user': 2,\n",
    "    'country': 3,\n",
    "    'lob': 4,\n",
    "    'sector': 5\n",
    "}\n",
    "\n",
    "TXN_TYPE_MAPPINGS = {\n",
    "    'DEPOSIT-CASH':0,\n",
    "    'DEPOSIT-CHECK':1,\n",
    "    'EXCHANGE': 2,\n",
    "    'MAKE-PAYMENT': 3,\n",
    "    'MOVE-FUNDS': 4,\n",
    "    'PAY-CHECK': 5,\n",
    "    'QUICK-PAYMENT': 6,\n",
    "    'WITHDRAWAL': 7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_nodes(nodes, index_mappings):\n",
    "    next_idx = len(data.x)\n",
    "    for index, t in enumerate(nodes):\n",
    "        data.y.append(t['label'])\n",
    "        data.x.append(t['features'])\n",
    "        index_mappings[t['id']] = next_idx + index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_nodes(tx, type, index_mappings):\n",
    "    raw_nodes = list(tx.run(f\"MATCH (n:{type}) RETURN properties(n)\"))\n",
    "    nodes = []\n",
    "    for node in raw_nodes:\n",
    "        props = node[0]\n",
    "        node_id = ''\n",
    "        if 'id' in props:\n",
    "            node_id = props['id']\n",
    "        elif 'name' in props:\n",
    "            node_id = props['name']\n",
    "        node_features = []\n",
    "        node_label = -1\n",
    "        node_features.append(NODE_TYPE_MAPPINGS[type.lower()])\n",
    "        if type.lower() == 'transaction':\n",
    "            node_label = int(props['isFraud'])\n",
    "            node_features.append(float(props['amount']))\n",
    "            import time\n",
    "            from datetime import datetime\n",
    "\n",
    "            date_time_str = props['ts']\n",
    "            date_time_obj = datetime.strptime(\n",
    "                date_time_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            timestamp = int(time.mktime(date_time_obj.timetuple()))\n",
    "\n",
    "            node_features.append(timestamp)\n",
    "            node_features.append(TXN_TYPE_MAPPINGS[props['type']])\n",
    "        else:\n",
    "            node_features += [-1,-1,-1]\n",
    "\n",
    "        nodes.append(\n",
    "            {'id': node_id, 'features': node_features, 'label': node_label})\n",
    "    insert_nodes(nodes, index_mappings)\n",
    "\n",
    "def fetch_nodes(tx):\n",
    "    _fetch_nodes(tx, 'Transaction', transaction_index_mappings)\n",
    "    _fetch_nodes(tx, 'User', user_index_mappings)\n",
    "    _fetch_nodes(tx, 'Account', account_index_mappings)\n",
    "    _fetch_nodes(tx, 'Country', country_index_mappings)\n",
    "    _fetch_nodes(tx, 'Lob', lob_index_mappings)\n",
    "    _fetch_nodes(tx, 'Sector', sector_index_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = []\n",
    "data.y = []\n",
    "with driver.session() as session:\n",
    "    session.execute_read(fetch_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y = torch.from_numpy(np.array(data.y))\n",
    "data.x = torch.from_numpy(np.array(data.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = {\n",
    "    'src': [],\n",
    "    'dst': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_edges(edges, a, b, a_mappings, b_mappings):\n",
    "    edge_index['src'] += [a_mappings[e[0][a]]for e in edges]\n",
    "    edge_index['dst'] += [b_mappings[e[0][b]]for e in edges]\n",
    "    \n",
    "def fetch_edges(tx):\n",
    "    belongs_to = list(tx.run(f\"MATCH p=()-[r:BELONGS_TO]->() RETURN p\"))\n",
    "    # from_country = list(tx.run(\"MATCH ()-[r:FROM]->() RETURN r\"))\n",
    "    # lob_in = list(tx.run(\"MATCH ()-[r:LOB_IN]->() RETURN r\"))\n",
    "    # received_by = list(\n",
    "    #     tx.run(f\"MATCH ()-[r:RECEIVED_BY]->() RETURN properties(r)\"))\n",
    "    # transferred_by = list(\n",
    "    #     tx.run(f\"MATCH ()-[r:TRANSFERRED_BY]->() RETURN properties(r)\"))\n",
    "    # works_in = list(tx.run(\"MATCH ()-[r:WORKS_IN]->() RETURN r\"))\n",
    "    \n",
    "    # construct_edges(belongs_to, 'account_id', 'user_id', account_index_mappings, user_index_mappings)\n",
    "    # construct_edges(from_country, 'account_id', 'country', account_index_mappings, country_index_mappings)\n",
    "    # construct_edges(lob_in, 'account_id', 'lob_name', account_index_mappings, lob_index_mappings)\n",
    "    # construct_edges(received_by, 'txn_id', 'account_id', transaction_index_mappings, account_index_mappings)\n",
    "    # construct_edges(transferred_by, 'txn_id', 'account_id',\n",
    "    #                 transaction_index_mappings, account_index_mappings)\n",
    "    # construct_edges(works_in, 'account_id', 'sector_id', account_index_mappings, sector_index_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.execute_read(fetch_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index = torch.stack([torch.from_numpy(np.array(edge_index['src'])), torch.from_numpy(np.array(edge_index['dst']))], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2142726, 4], y=[2142726], edge_index=[2, 8592098])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "==============\n",
      "Data(x=[2142726, 4], y=[2142726], edge_index=[2, 4811576], edge_label=[2062104], edge_label_index=[2, 2062104])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(\"==============\")\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygod in /home/hieu/.local/lib/python3.8/site-packages (0.3.1)\n",
      "Requirement already satisfied: scipy>=1.5.2 in /home/hieu/.local/lib/python3.8/site-packages (from pygod) (1.10.1)\n",
      "Requirement already satisfied: setuptools>=50.3.1.post20201107 in /home/hieu/.local/lib/python3.8/site-packages (from pygod) (67.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /home/hieu/.local/lib/python3.8/site-packages (from pygod) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /home/hieu/.local/lib/python3.8/site-packages (from pygod) (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hieu/.local/lib/python3.8/site-packages (from scikit-learn>=0.22.1->pygod) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/hieu/.local/lib/python3.8/site-packages (from scikit-learn>=0.22.1->pygod) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install pygod   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3409709"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 18365098844304 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpygod\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m DOMINANT\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m DOMINANT(num_layers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, epoch\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, num_neigh\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)  \u001b[39m# hyperparameters can be set here\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mfit(val_data)  \u001b[39m# data is a Pytorch Geometric data object\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# get outlier scores on the input data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m outlier_scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecision_scores_  \u001b[39m# raw outlier scores on the input data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pygod/models/dominant.py:130\u001b[0m, in \u001b[0;36mDOMINANT.fit\u001b[0;34m(self, G, y_true)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39mFit detector with input data.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m G\u001b[39m.\u001b[39mnode_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(G\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 130\u001b[0m G\u001b[39m.\u001b[39ms \u001b[39m=\u001b[39m to_dense_adj(G\u001b[39m.\u001b[39;49medge_index)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    132\u001b[0m \u001b[39m# automated balancing by std\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/utils/to_dense_adj.py:88\u001b[0m, in \u001b[0;36mto_dense_adj\u001b[0;34m(edge_index, batch, edge_attr, max_num_nodes)\u001b[0m\n\u001b[1;32m     86\u001b[0m size \u001b[39m=\u001b[39m [batch_size, max_num_nodes, max_num_nodes]\n\u001b[1;32m     87\u001b[0m size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(edge_attr\u001b[39m.\u001b[39msize())[\u001b[39m1\u001b[39m:]\n\u001b[0;32m---> 88\u001b[0m adj \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(size, dtype\u001b[39m=\u001b[39;49medge_attr\u001b[39m.\u001b[39;49mdtype, device\u001b[39m=\u001b[39;49medge_index\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     90\u001b[0m flattened_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m max_num_nodes \u001b[39m*\u001b[39m max_num_nodes\n\u001b[1;32m     91\u001b[0m adj \u001b[39m=\u001b[39m adj\u001b[39m.\u001b[39mview([flattened_size] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(adj\u001b[39m.\u001b[39msize())[\u001b[39m3\u001b[39m:])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 18365098844304 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "# train a dominant detector\n",
    "from pygod.models import DOMINANT\n",
    "\n",
    "model = DOMINANT(num_layers=4, epoch=20, batch_size=128, num_neigh=10)  # hyperparameters can be set here\n",
    "model.fit(val_data)  # data is a Pytorch Geometric data object\n",
    "\n",
    "# get outlier scores on the input data\n",
    "outlier_scores = model.decision_scores_  # raw outlier scores on the input data\n",
    "print(outlier_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the new data in the inductive setting\n",
    "# raw outlier scores on the input data\n",
    "outlier_scores = model.decision_function(test_data)\n",
    "print(outlier_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.5580\n",
      "Epoch: 002, Loss: 0.3737\n",
      "Epoch: 003, Loss: 0.2478\n",
      "Epoch: 004, Loss: 0.1645\n",
      "Epoch: 005, Loss: 0.1104\n",
      "Epoch: 006, Loss: 0.0755\n",
      "Epoch: 007, Loss: 0.0528\n",
      "Epoch: 008, Loss: 0.0378\n",
      "Epoch: 009, Loss: 0.0276\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model = model.to('cuda:0')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    total_loss = total_examples = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(train_data)\n",
    "\n",
    "    ground_truth = train_data[\"transaction\", \"received_by\", \"account\"].edge_label\n",
    "    loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += float(loss) * pred.numel()\n",
    "    total_examples += pred.numel()\n",
    "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
